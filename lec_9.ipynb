{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcmMwU/Gao8l8XIkqEcXuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jellybeanJoo/PyTorchZeroToAll/blob/main/lec_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkgIOKgxOdkq"
      },
      "source": [
        "from__future__ import print_function\n",
        "from torch import nn,optim,cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets,transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "batch_size=64\n",
        "device='cuda'if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}')\n",
        "\n",
        "train_dataset=datasets.MNIST(root='./mnist_data/',train=True,transform=transfroms.Totensor(),\n",
        "                             download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/'train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = data.DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = nn.Linear(784, 520)\n",
        "    self.l2 = nn.Linear(520, 320)\n",
        "    self.l3 = nn.Linear(320, 240)\n",
        "    self.l4 = nn.Linear(240, 120)\n",
        "    self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
        "    x = F.relu(self.l1(x))\n",
        "    x = F.relu(self.l2(x))\n",
        "    x = F.relu(self.l3(x))\n",
        "    x = F.relu(self.l4(x))\n",
        "    return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    test_loss += criterion(output, target).item()\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "        f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  since = time.time()\n",
        "  for epoch in range(1, 10):\n",
        "    epoch_start = time.time()\n",
        "    train(epoch)\n",
        "    m, s = divmod(time.time() - epoch_start, 60)\n",
        "    print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "    test()\n",
        "    m, s = divmod(time.time() - epoch_start, 60)\n",
        "    print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "  m, s = divmod(time.time() - since, 60)\n",
        "  print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}