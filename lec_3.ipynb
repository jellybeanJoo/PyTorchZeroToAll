{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCMhwHCf4/d1Ic8iGrZc2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jellybeanJoo/PyTorchZeroToAll/blob/main/lec_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU0i5o8fW6wI"
      },
      "source": [
        "x_data=[1.0,2.0,3.0]\n",
        "y_data=[2.0,4.0,6.0]\n",
        "w=1.0\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "def loss(x,y):\n",
        "  y_pred=forward(x)\n",
        "  return (y_pred-y)**2\n",
        "\n",
        "def gradient(x,y):\n",
        "  return 2*x*(w*x-y)\n",
        "\n",
        "print(\"predict before training\",4,forward(4))\n",
        "\n",
        "for epoch in range(100):\n",
        "  for x_val,y_val in zip(x_data,y_data):\n",
        "    grad=gradient(x_val,y_val)\n",
        "    w=w-0.01*grad\n",
        "    l=loss(x_val,y_val)\n",
        "  print(\"progress:\",epoch,'w=',w, 'loss=',l)\n",
        "\n",
        "print(\"predict after training\",4,forward(4))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9erz_-lIyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e717245b-96c0-4a1a-dc3e-f4fb0052ac99"
      },
      "source": [
        "#exercise 3-1,3-2\n",
        "#answer w2=2, w1=3\n",
        "x_data=[1.0,2.0,3.0]\n",
        "y_data=[5.0,14.0,27.0]\n",
        "w2=1.0;w1=1.0;b=0\n",
        "\n",
        "def forward(x):\n",
        "  return w2*x*x+x*w1+b\n",
        "\n",
        "def loss(x,y):\n",
        "  y_pred=forward(x)\n",
        "  return (y_pred-y)**2\n",
        "\n",
        "#gradient2=2*x*x(w2*x*x+x*w1+b-y)\n",
        "def gradient2(x,y):\n",
        "  return 2*x*x*(w2*x*x+x*w1+b-y)\n",
        "\n",
        "#gradient1=2*x(w2*x*x+x*w1+b-y)\n",
        "def gradient1(x,y):\n",
        "  return 2*x*(w2*x*x+x*w1+b-y)\n",
        "\n",
        "print(\"predict before training:\",4,forward(4))\n",
        "\n",
        "for epoch in range(100):\n",
        "  for x_val,y_val in zip(x_data,y_data):\n",
        "    grad2=gradient2(x_val,y_val)\n",
        "    w2=w2-0.01*grad2\n",
        "    l=loss(x_val,y_val)\n",
        "  print(\"progress:\",epoch,'w2=',w2,'loss=',l)\n",
        "\n",
        "print(\"predict after training w2:\",4,forward(4))\n",
        "\n",
        "for epoch in range(100):\n",
        "  for x_val,y_val in zip(x_data,y_data):\n",
        "    grad1=gradient1(x_val,y_val)\n",
        "    w1=w1-0.01*grad1\n",
        "    l=loss(x_val,y_val)\n",
        "  print(\"progress:\",epoch,'w1=',w1,'loss=',l)\n",
        "\n",
        "print(\"predict after training w1 and w2\",4,forward(4))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict before training: 4 20.0\n",
            "progress: 0 w2= 3.2779039999999995 loss= 30.26249729049595\n",
            "progress: 1 w2= 2.336746960128 loss= 8.816608033767356\n",
            "progress: 2 w2= 2.7256029319778343 loss= 0.28135215287509724\n",
            "progress: 3 w2= 2.564940087800582 loss= 0.838212044671617\n",
            "progress: 4 w2= 2.63132083380361 loss= 0.10119555996343513\n",
            "progress: 5 w2= 2.60389443373903 loss= 0.31916861136444075\n",
            "progress: 6 w2= 2.615226144600912 loss= 0.21433631214219037\n",
            "progress: 7 w2= 2.610544244287531 loss= 0.25512782978987325\n",
            "progress: 8 w2= 2.612478655676209 loss= 0.23784358334325678\n",
            "progress: 9 w2= 2.611679418791572 loss= 0.24491139173904514\n",
            "progress: 10 w2= 2.612009637896724 loss= 0.24197865431062765\n",
            "progress: 11 w2= 2.6118732019294866 loss= 0.24318822601027157\n",
            "progress: 12 w2= 2.6119295729051974 loss= 0.2426881041095986\n",
            "progress: 13 w2= 2.6119062822219057 loss= 0.24289467606757967\n",
            "progress: 14 w2= 2.6119159051869403 loss= 0.24280931649140117\n",
            "progress: 15 w2= 2.6119119292857227 loss= 0.24284458251814897\n",
            "progress: 16 w2= 2.6119135720008773 loss= 0.2428300114139535\n",
            "progress: 17 w2= 2.611912893283542 loss= 0.2428360316749364\n",
            "progress: 18 w2= 2.6119131737078254 loss= 0.24283354428670353\n",
            "progress: 19 w2= 2.611913057845485 loss= 0.24283457199438052\n",
            "progress: 20 w2= 2.6119131057160967 loss= 0.2428341473781885\n",
            "progress: 21 w2= 2.6119130859374917 loss= 0.24283432281596898\n",
            "progress: 22 w2= 2.6119130941093784 loss= 0.24283425033068345\n",
            "progress: 23 w2= 2.6119130907330166 loss= 0.24283428027928214\n",
            "progress: 24 w2= 2.6119130921280203 loss= 0.24283426790548782\n",
            "progress: 25 w2= 2.61191309155165 loss= 0.24283427301793675\n",
            "progress: 26 w2= 2.611913091789788 loss= 0.2428342709056303\n",
            "progress: 27 w2= 2.6119130916913966 loss= 0.24283427177837524\n",
            "progress: 28 w2= 2.6119130917320486 loss= 0.24283427141779118\n",
            "progress: 29 w2= 2.6119130917152535 loss= 0.24283427156676293\n",
            "progress: 30 w2= 2.6119130917221915 loss= 0.24283427150522183\n",
            "progress: 31 w2= 2.6119130917193254 loss= 0.24283427153064222\n",
            "progress: 32 w2= 2.61191309172051 loss= 0.24283427152013792\n",
            "progress: 33 w2= 2.61191309172002 loss= 0.2428342715244797\n",
            "progress: 34 w2= 2.6119130917202225 loss= 0.24283427152268697\n",
            "progress: 35 w2= 2.6119130917201385 loss= 0.24283427152342926\n",
            "progress: 36 w2= 2.611913091720174 loss= 0.24283427152311413\n",
            "progress: 37 w2= 2.6119130917201585 loss= 0.24283427152325418\n",
            "progress: 38 w2= 2.6119130917201656 loss= 0.24283427152319118\n",
            "progress: 39 w2= 2.6119130917201625 loss= 0.24283427152321918\n",
            "progress: 40 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 41 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 42 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 43 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 44 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 45 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 46 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 47 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 48 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 49 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 50 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 51 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 52 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 53 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 54 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 55 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 56 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 57 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 58 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 59 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 60 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 61 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 62 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 63 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 64 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 65 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 66 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 67 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 68 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 69 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 70 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 71 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 72 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 73 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 74 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 75 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 76 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 77 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 78 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 79 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 80 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 81 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 82 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 83 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 84 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 85 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 86 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 87 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 88 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 89 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 90 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 91 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 92 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 93 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 94 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 95 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 96 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 97 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "progress: 98 w2= 2.611913091720164 loss= 0.24283427152320516\n",
            "progress: 99 w2= 2.611913091720163 loss= 0.24283427152321568\n",
            "predict after training w2: 4 45.79060946752261\n",
            "progress: 0 w1= 1.101427388109553 loss= 0.03553225384158367\n",
            "progress: 1 w1= 1.1764138732676028 loss= 0.0013292911504368503\n",
            "progress: 2 w1= 1.231852281582771 loss= 0.04111756688679563\n",
            "progress: 3 w1= 1.2728385621110745 loss= 0.10610232071913066\n",
            "progress: 4 w1= 1.3031402111410157 loss= 0.17358760543832638\n",
            "progress: 5 w1= 1.3255425838886394 loss= 0.23410654252508573\n",
            "progress: 6 w1= 1.3421049268894307 loss= 0.28465704182495\n",
            "progress: 7 w1= 1.3543496658180318 loss= 0.3252042493410192\n",
            "progress: 8 w1= 1.3634023482448139 loss= 0.3569164755524929\n",
            "progress: 9 w1= 1.3700951049951229 loss= 0.38131012848640233\n",
            "progress: 10 w1= 1.3750431403737071 loss= 0.39986304028587016\n",
            "progress: 11 w1= 1.378701282305519 loss= 0.4138627741769902\n",
            "progress: 12 w1= 1.3814057905334105 loss= 0.4243678159968682\n",
            "progress: 13 w1= 1.3834052659203895 loss= 0.43221896896993484\n",
            "progress: 14 w1= 1.384883502067688 loss= 0.43806968848686384\n",
            "progress: 15 w1= 1.3859763797902194 loss= 0.4424204848519921\n",
            "progress: 16 w1= 1.3867843574050196 loss= 0.4456509034513438\n",
            "progress: 17 w1= 1.3873817049513726 loss= 0.4480467458946951\n",
            "progress: 18 w1= 1.387823331160562 loss= 0.44982215050555036\n",
            "progress: 19 w1= 1.3881498307165303 loss= 0.4511369855736966\n",
            "progress: 20 w1= 1.3883912157562524 loss= 0.4521102926272105\n",
            "progress: 21 w1= 1.3885696746127392 loss= 0.45283054453531585\n",
            "progress: 22 w1= 1.3887016113868464 loss= 0.4533634039873818\n",
            "progress: 23 w1= 1.388799153827185 loss= 0.4537575548302722\n",
            "progress: 24 w1= 1.3888712681238367 loss= 0.45404906539031903\n",
            "progress: 25 w1= 1.388924583088723 loss= 0.45426464283079243\n",
            "progress: 26 w1= 1.3889639994820429 loss= 0.4544240547156921\n",
            "progress: 27 w1= 1.388993140494621 loss= 0.454541927815627\n",
            "progress: 28 w1= 1.389014684794912 loss= 0.454629082640703\n",
            "progress: 29 w1= 1.389030612754649 loss= 0.45469352262045004\n",
            "progress: 30 w1= 1.389042388486418 loss= 0.4547411668068364\n",
            "progress: 31 w1= 1.3890510944262235 loss= 0.4547763923303726\n",
            "progress: 32 w1= 1.389057530831993 loss= 0.45480243585979346\n",
            "progress: 33 w1= 1.3890622893440154 loss= 0.4548216906330546\n",
            "progress: 34 w1= 1.3890658073690556 loss= 0.4548359261800382\n",
            "progress: 35 w1= 1.3890684082871843 loss= 0.45484645083397823\n",
            "progress: 36 w1= 1.3890703311771677 loss= 0.45485423191522484\n",
            "progress: 37 w1= 1.3890717527928071 loss= 0.4548599846047593\n",
            "progress: 38 w1= 1.3890728038103088 loss= 0.4548642376605481\n",
            "progress: 39 w1= 1.3890735808401602 loss= 0.45486738200851584\n",
            "progress: 40 w1= 1.3890741553076533 loss= 0.45486970666968296\n",
            "progress: 41 w1= 1.3890745800183646 loss= 0.4548714253234031\n",
            "progress: 42 w1= 1.3890748940120903 loss= 0.45487269594681057\n",
            "progress: 43 w1= 1.3890751261514194 loss= 0.45487363533508396\n",
            "progress: 44 w1= 1.389075297774811 loss= 0.4548743298367275\n",
            "progress: 45 w1= 1.3890754246580441 loss= 0.4548748432904735\n",
            "progress: 46 w1= 1.3890755184643409 loss= 0.45487522289316995\n",
            "progress: 47 w1= 1.3890755878164616 loss= 0.4548755035381034\n",
            "progress: 48 w1= 1.3890756390893166 loss= 0.45487571102232477\n",
            "progress: 49 w1= 1.3890756769959536 loss= 0.4548758644179285\n",
            "progress: 50 w1= 1.3890757050207854 loss= 0.45487597782515926\n",
            "progress: 51 w1= 1.3890757257398798 loss= 0.45487606166849426\n",
            "progress: 52 w1= 1.3890757410577548 loss= 0.4548761236548793\n",
            "progress: 53 w1= 1.3890757523824437 loss= 0.45487616948216436\n",
            "progress: 54 w1= 1.389075760754922 loss= 0.45487620336282397\n",
            "progress: 55 w1= 1.3890757669447957 loss= 0.4548762284112061\n",
            "progress: 56 w1= 1.3890757715210438 loss= 0.45487624692977574\n",
            "progress: 57 w1= 1.3890757749043188 loss= 0.4548762606207773\n",
            "progress: 58 w1= 1.3890757774056146 loss= 0.45487627074269577\n",
            "progress: 59 w1= 1.389075779254853 loss= 0.45487627822595506\n",
            "progress: 60 w1= 1.3890757806220166 loss= 0.4548762837584162\n",
            "progress: 61 w1= 1.3890757816327775 loss= 0.4548762878486345\n",
            "progress: 62 w1= 1.3890757823800448 loss= 0.45487629087257875\n",
            "progress: 63 w1= 1.3890757829325087 loss= 0.4548762931082218\n",
            "progress: 64 w1= 1.3890757833409517 loss= 0.4548762947610541\n",
            "progress: 65 w1= 1.3890757836429184 loss= 0.454876295983013\n",
            "progress: 66 w1= 1.389075783866166 loss= 0.4548762968864234\n",
            "progress: 67 w1= 1.3890757840312158 loss= 0.45487629755432485\n",
            "progress: 68 w1= 1.3890757841532388 loss= 0.45487629804811053\n",
            "progress: 69 w1= 1.3890757842434522 loss= 0.4548762984131771\n",
            "progress: 70 w1= 1.389075784310148 loss= 0.4548762986830702\n",
            "progress: 71 w1= 1.389075784359457 loss= 0.4548762988826088\n",
            "progress: 72 w1= 1.3890757843959116 loss= 0.4548762990301277\n",
            "progress: 73 w1= 1.3890757844228632 loss= 0.45487629913919386\n",
            "progress: 74 w1= 1.3890757844427886 loss= 0.45487629921982775\n",
            "progress: 75 w1= 1.3890757844575197 loss= 0.45487629927943823\n",
            "progress: 76 w1= 1.3890757844684107 loss= 0.45487629932351226\n",
            "progress: 77 w1= 1.3890757844764625 loss= 0.4548762993560898\n",
            "progress: 78 w1= 1.3890757844824155 loss= 0.4548762993801851\n",
            "progress: 79 w1= 1.3890757844868167 loss= 0.45487629939799296\n",
            "progress: 80 w1= 1.3890757844900705 loss= 0.454876299411162\n",
            "progress: 81 w1= 1.389075784492476 loss= 0.4548762994208902\n",
            "progress: 82 w1= 1.3890757844942543 loss= 0.4548762994280881\n",
            "progress: 83 w1= 1.3890757844955688 loss= 0.4548762994334075\n",
            "progress: 84 w1= 1.3890757844965407 loss= 0.4548762994373419\n",
            "progress: 85 w1= 1.3890757844972594 loss= 0.45487629944025076\n",
            "progress: 86 w1= 1.3890757844977908 loss= 0.4548762994423977\n",
            "progress: 87 w1= 1.3890757844981836 loss= 0.4548762994439887\n",
            "progress: 88 w1= 1.389075784498474 loss= 0.4548762994451676\n",
            "progress: 89 w1= 1.3890757844986887 loss= 0.45487629944603497\n",
            "progress: 90 w1= 1.3890757844988473 loss= 0.4548762994466771\n",
            "progress: 91 w1= 1.3890757844989647 loss= 0.4548762994471516\n",
            "progress: 92 w1= 1.3890757844990513 loss= 0.4548762994475014\n",
            "progress: 93 w1= 1.3890757844991155 loss= 0.4548762994477602\n",
            "progress: 94 w1= 1.389075784499163 loss= 0.45487629944795666\n",
            "progress: 95 w1= 1.389075784499198 loss= 0.45487629944809566\n",
            "progress: 96 w1= 1.3890757844992239 loss= 0.45487629944820107\n",
            "progress: 97 w1= 1.3890757844992432 loss= 0.45487629944827773\n",
            "progress: 98 w1= 1.3890757844992572 loss= 0.45487629944833524\n",
            "progress: 99 w1= 1.3890757844992678 loss= 0.4548762994483784\n",
            "predict after training w1 and w2 4 47.34691260551968\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}